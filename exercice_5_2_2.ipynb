{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37cbbb7f",
   "metadata": {
    "editable": false,
    "id": "30301e0d",
    "lang": "fr",
    "tags": [
     "problem-title"
    ]
   },
   "source": [
    "# Devoir 2, Question 2 : Discriminants linéaires"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a0836",
   "metadata": {
    "editable": false,
    "id": "b48d091a",
    "lang": "en",
    "tags": [
     "problem-title"
    ]
   },
   "source": [
    "# Homework 2, Question 2: Linear discriminants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66196425",
   "metadata": {
    "editable": false,
    "id": "6d273f2d",
    "lang": "fr",
    "tags": [
     "problem-statement"
    ]
   },
   "source": [
    "Soit un discriminant linéaire, avec lequel le classement est effectué selon:\n",
    "\\begin{equation*}\n",
    "\\mathrm{h}(\\mathbf{x}|\\mathbf{w},w_0) = \\mathbf{w}^\\top \\mathbf{x} + w_0,\\quad \\mathbf{x}^t\\in\\left\\{\\begin{array}{cc}C_1 & \\mathrm{h}(\\mathbf{x}^t|\\mathbf{w},w_0)\\geq 0\\\\ C_2 & \\mbox{autrement}\\end{array}\\right..\n",
    "\\end{equation*}\n",
    "\n",
    "On effectue un entraînement avec une descente du gradient basée sur le critère d'erreur suivant:\n",
    "\\begin{equation*}\n",
    "E(\\mathbf{w},w_0|\\mathcal{X}) = \\frac{1}{2} \\sum_{\\mathbf{x}^t\\in\\mathcal{Y}} \\frac{[r^t - \\mathrm{h}(\\mathbf{x}^t|\\mathbf{w},w_0)]^2}{\\|\\mathbf{x}^t\\|^2},\n",
    "\\end{equation*}\n",
    "où $r^t\\in\\{-1,1\\}$ et $\\mathcal{Y}$ est l'ensemble des données de $\\mathcal{X}$ mal classées,\n",
    "\\begin{equation*}\n",
    "\\mathcal{Y} = \\{\\mathbf{x}^t\\in\\mathcal{X}~|~r^t \\mathrm{h}(\\mathbf{x}^t|\\mathbf{w},w_0)\\leq 0\\}.\n",
    "\\end{equation*}\n",
    "Si l'ensemble $\\mathcal{Y}$ est vide, alors $E(\\mathbf{w},w_0|\\mathcal{X})=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6b18e0",
   "metadata": {
    "editable": false,
    "id": "cb1d3273",
    "lang": "en",
    "tags": [
     "problem-statement"
    ]
   },
   "source": [
    "Let a linear discriminant, for which classification is done as:\n",
    "\\begin{equation*}\n",
    "\\mathrm{h}(\\mathbf{x}|\\mathbf{w},w_0) = \\mathbf{w}^\\top \\mathbf{x} + w_0,\\quad \\mathbf{x}^t\\in\\left\\{\\begin{array}{cc}C_1 & \\mathrm{h}(\\mathbf{x}^t|\\mathbf{w},w_0)\\geq 0\\\\ C_2 & \\mbox{otherwise}\\end{array}\\right..\n",
    "\\end{equation*}\n",
    "\n",
    "Training is done by gradient descent based on the following error criterion:\n",
    "\\begin{equation*}\n",
    "E(\\mathbf{w},w_0|\\mathcal{X}) = \\frac{1}{2} \\sum_{\\mathbf{x}^t\\in\\mathcal{Y}} \\frac{[r^t - \\mathrm{h}(\\mathbf{x}^t|\\mathbf{w},w_0)]^2}{\\|\\mathbf{x}^t\\|^2},\n",
    "\\end{equation*}\n",
    "where $r^t\\in\\{-1,1\\}$ and $\\mathcal{Y}$ is the set of instances from $\\mathcal{X}$ that are misclassified,\n",
    "\\begin{equation*}\n",
    "\\mathcal{Y} = \\{\\mathbf{x}^t\\in\\mathcal{X}~|~r^t \\mathrm{h}(\\mathbf{x}^t|\\mathbf{w},w_0)\\leq 0\\}.\n",
    "\\end{equation*}\n",
    "If the set $\\mathcal{Y}$ is empty, then $E(\\mathbf{w},w_0|\\mathcal{X})=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883fe711",
   "metadata": {
    "editable": false,
    "id": "ce7c576c",
    "lang": "fr",
    "tags": [
     "problem-statement"
    ]
   },
   "source": [
    "## Code préambule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e558b70",
   "metadata": {
    "editable": false,
    "id": "c8278eac",
    "lang": "en",
    "tags": [
     "problem-statement"
    ]
   },
   "source": [
    "## Preamble code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc7d14",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-05T00:16:49.136Z"
    },
    "editable": false,
    "id": "37f50c11",
    "tags": [
     "problem-context",
     "autoexec"
    ]
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy\n",
    "import pandas\n",
    "pandas.set_option('display.max_colwidth', 0)\n",
    "import collections\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib notebook\n",
    "matplotlib.rcParams['figure.figsize'] = (15.0, 10.0)\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "_times = []\n",
    "def checkTime(maxduration, question):\n",
    "    duration = _times[-1] - _times[-2]\n",
    "    if duration > maxduration:\n",
    "        print(\"[ATTENTION] Votre code pour la question {0} met trop de temps à s'exécuter! \".format(question)+\n",
    "            \"Le temps maximum permis est de {0:.4f} secondes, mais votre code a requis {1:.4f} secondes! \".format(maxduration,duration)+\n",
    "            \"Assurez-vous que vous ne faites pas d'appels bloquants (par exemple à show()) dans cette boucle!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66ba1af",
   "metadata": {
    "editable": false,
    "id": "0338d41b",
    "lang": "fr",
    "tags": [
     "problem-statement"
    ]
   },
   "source": [
    "## Q2A\n",
    "Donnez le développement mathématique __<u>complet</u>__ des équations permettant d'effectuer la mise à jour des poids $\\mathbf{w}$ et $w_0$ par descente du gradient, selon le critère d'erreur proposé."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c668bf6a",
   "metadata": {
    "editable": false,
    "id": "34a2d6e7",
    "lang": "en",
    "tags": [
     "problem-statement"
    ]
   },
   "source": [
    "## Q2A\n",
    "Provide the __<u>complete</u>__ mathematical development of the equations to update the weights $\\mathbf{w}$ et $w_0$ by gradient descent, using the proposed error criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00346590",
   "metadata": {
    "editable": false,
    "id": "59956bc3",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "### Entrez votre solution à Q2A dans la cellule ci-dessous (markdown et $\\LaTeX$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47691c42",
   "metadata": {
    "editable": false,
    "id": "b97c2ed4",
    "lang": "en",
    "tags": []
   },
   "source": [
    "### Enter your answer to Q2A in the cell below (markdown and $\\LaTeX$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d44fa",
   "metadata": {
    "editable": false,
    "tags": [
     "feedback"
    ]
   },
   "source": [
    "<div class=\"feedback-cell\" style=\"background: rgba(100 , 100 , 100 , 0.4)\">\n",
    "            <h3>Votre soumission a été enregistrée!</h3><ul><li>notez qu'il n'y a\n",
    "            <strong>pas</strong> de correction automatique pour cet exercice&puncsp;;</li>\n",
    "            <li>par conséquent, votre note est <strong>actuellement</strong> zéro&puncsp;;</li>\n",
    "            <li>elle sera cependant ajustée par le professeur dès que la correction manuelle\n",
    "            sera complétée&puncsp;;</li><li>vous pouvez soumettre autant de fois que nécessaire\n",
    "            jusqu'à la date d'échéance&puncsp;;</li><li>mais évitez de soumettre inutilement.</li>\n",
    "            </ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3b8c96",
   "metadata": {
    "deletable": false,
    "id": "93372ea1",
    "tags": [
     "user-answer-D2Q2A",
     "editable"
    ]
   },
   "source": [
    "$h_i(\\mathbf{x^t}|w_{i,j},w_0) = \\sum_{j=1}^{D}x_j^t w_{i,j} + w_{i,0}$\n",
    "\n",
    "Avec,\n",
    "$E(\\mathbf{w},w_0|\\mathcal{X}) = \n",
    "\\frac{1}{2} \\sum_{\\mathbf{x}^t\\in\\mathcal{Y}} \\frac{[r^t - \\mathrm{h}(\\mathbf{x}^t|\\mathbf{w},w_0)]^2}{\\|\\mathbf{x}^t\\|^2}$\n",
    "\n",
    "On obtient les dérivées partielles suivantes:\n",
    "\n",
    "$\\begin{align*}\n",
    "\\frac{\\partial E(w_i,w_0|\\mathcal{X}) }{\\partial w_i} \n",
    "&= \\frac{\\partial E(w_i,w_0|\\mathcal{X})}{\\partial h_i}\\frac{\\partial h_i(\\mathbf{x^t}|w_{i,j},w_0)}{\\partial w_i} \\\\\n",
    "&= \\frac{1}{2}\\sum_{\\mathbf{x}^t\\in\\mathcal{Y}} 2\\frac{r^t - h_i(\\mathbf{x^t}|w_{i,j},w_0)}{\\|\\mathbf{x}^t\\|^2} \\frac{\\partial(r^t - h_i(\\mathbf{x^t}|w_{i,j},w_0))}{\\partial w_j} \\\\\n",
    "&= -\\sum_{\\mathbf{x}^t\\in\\mathcal{Y}}\\mathbf{x_j^t}\\frac{r^t - (\\mathbf{x^t}\\mathbf{w} + w_0)}{\\|\\mathbf{x}^t\\|^2}\n",
    "\\end{align*}$\n",
    "\n",
    "De même,\n",
    "$\\frac{\\partial E(w_i,w_0|\\mathcal{X}) }{\\partial w_0} = \n",
    "-\\sum_{\\mathbf{x}^t\\in\\mathcal{Y}}\\frac{r^t - h_i(\\mathbf{x^t}|w_{i,j},w_0)}{\\|\\mathbf{x}^t\\|^2}$\n",
    "\n",
    "Si on pose:\n",
    "$e(x^t) = \\frac{r^t - h_i(\\mathbf{x^t}|w_{i,j},w_0)}{\\|\\mathbf{x}^t\\|^2}$, alors:\n",
    "$\\Delta w_i = -\\eta\\frac{\\partial E(w_i,w_0|\\mathcal{X}) }{\\partial w_i} = \\eta\\sum_{\\mathbf{x}^t\\in\\mathcal{Y}}e(x^t)x^t \\\\\n",
    "\\Delta w_0 = -\\eta\\frac{\\partial E(w_i,w_0|\\mathcal{X}) }{\\partial w_0} = \\eta\\sum_{\\mathbf{x}^t\\in\\mathcal{Y}}e(x^t)$\n",
    "\n",
    "On peut donc écrire les relations: \n",
    "$w_{i,j} = w_{i,j} + \\eta\\sum_{\\mathbf{x}^t\\in\\mathcal{Y}}e(\\mathbf{x^t})\\mathbf{x^t}, j=1,..., D\\\\\n",
    "w_{i,0} = w_{i,0} + \\eta\\sum_{\\mathbf{x}^t\\in\\mathcal{Y}}e(\\mathbf{x^t})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6976de6",
   "metadata": {
    "editable": false,
    "id": "37bdda37",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "## Q2B\n",
    "Implémentez une classe Python correspondant à ce discriminant linéaire, en programmant les fonctions `fit`, `predict` et `score` de l'interface *Scikit-learn*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86dbc12",
   "metadata": {
    "editable": false,
    "id": "333659cb",
    "lang": "en",
    "tags": []
   },
   "source": [
    "## Q2B\n",
    "Implement a Python class corresponding to this linear discriminant, by programming the `fit`, `predict` and `score` functions of the *Scikit-learn* interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dba797",
   "metadata": {
    "editable": false,
    "id": "ef92db17",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "### Patron de code réponse à l'exercice Q2B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2b0a71",
   "metadata": {
    "editable": false,
    "id": "a22a91e2",
    "lang": "en",
    "tags": []
   },
   "source": [
    "### Q2B answer code template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a762714",
   "metadata": {
    "editable": false,
    "id": "5407b298",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implémentation du discriminant linéaire\n",
    "# Implementation of the linear discriminant\n",
    "class DiscriminantLineaire:\n",
    "    def __init__(self, eta=1e-2, epsilon=1e-2, max_iter=1000):\n",
    "\n",
    "        # Cette fonction est déjà codée, utilisez les variables membres\n",
    "        # qu'elle définit dans les autres fonctions\n",
    "        # This function is already coded, use the member variables it\n",
    "        # defines in other functions\n",
    "        self.eta = eta\n",
    "        \n",
    "        # Epsilon et max_iter sont des paramètres du critère d'arrêt\n",
    "        # max_iter est le nombre maximum de mises à jour des poids,\n",
    "        # alors qu'epsilon est un seuil sur la différent minimale entre les\n",
    "        # erreurs faites entre deux itérations consécutives pour continuer l'entraînement\n",
    "        # Epsilon and max_iter are parameters for the stop criterion\n",
    "        # max_iter is the maximum number of weights updates allowed, while\n",
    "        # epsilon is a threshold on the minimum error difference observed between\n",
    "        # two consecutive training steps.\n",
    "        self.epsilon = epsilon\n",
    "        self.max_iter = max_iter\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Implémentez la fonction d'entraînement selon les équations développées\n",
    "        # à la question précédente.\n",
    "        # Implement the training function according to the equations developed at the\n",
    "        # previous question\n",
    "\n",
    "        # On initialise les poids aléatoirement\n",
    "        # Weights are randomly initialized\n",
    "        w = numpy.random.rand(X.shape[1]+1)\n",
    "\n",
    "        # *** TODO Q2B ***\n",
    "        # Implémentez ici l'entraînement dans la boucle suivante,\n",
    "        # qui se répète self.max_iter fois.\n",
    "        # Vous êtes libres d'utiliser les noms de variable de votre choix, sauf\n",
    "        # pour les poids qui doivent être contenus dans la variable w définie plus haut\n",
    "        # Implement here the training in the following loop, which is \n",
    "        # repeated self.max_iter times\n",
    "        # You are free to use the variables names of your choice, except\n",
    "        # for the weights, which should be put in variable w defined above\n",
    "        for i in range(self.max_iter):\n",
    "            # Retirez le \"pass\" et compléter le code ici\n",
    "            # Remove the \"pass\" and complete the code here\n",
    "            pass \n",
    "        # ******\n",
    "\n",
    "        # Copie des poids entraînés dans une variable membre pour les conserver\n",
    "        # Copy trained weights in a member variable for storing\n",
    "        self.w = w\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # *** TODO Q2B ***\n",
    "        # Implémentez la fonction de prédiction\n",
    "        # Implement the prediction function\n",
    "\n",
    "        # Retirez le \"pass\" et complétez le code ici\n",
    "        # Remove the \"pass\" and complete the code here\n",
    "        pass\n",
    "        # ******\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        # *** TODO Q2B ***\n",
    "        # Implémentez la fonction retournant le score (précision / accuracy)\n",
    "        # du classifieur sur les données reçues en argument.\n",
    "        # Vous pouvez supposer que fit() a préalablement été exécuté\n",
    "        # Indice : réutiliser votre implémentation de predict() réduit de\n",
    "        # beaucoup la taille de cette fonction!\n",
    "        # Implement the function returning the classifier score (accuracy)\n",
    "        # on data received as argument.\n",
    "        # You can assume that fit() has been executed before\n",
    "        # Tip: reusing your implementation of predict() reduce significantly the \n",
    "        # size of this function!\n",
    "\n",
    "        # Retirez le \"pass\" et complétez le code ici\n",
    "        # Remove the \"pass\" and complete the code here\n",
    "        pass\n",
    "        # ******\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a54f5f",
   "metadata": {
    "editable": false,
    "id": "aacb94ed",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "### Entrez votre solution à Q2B dans la cellule ci-dessous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7c2235",
   "metadata": {
    "editable": false,
    "id": "4440daf1",
    "lang": "en",
    "tags": []
   },
   "source": [
    "### Enter your answer to Q2B in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0808912",
   "metadata": {
    "deletable": false,
    "id": "4095781b",
    "tags": [
     "user-answer-D2Q2B",
     "editable"
    ]
   },
   "outputs": [],
   "source": [
    "# Implémentation du discriminant linéaire\n",
    "# Implementation of the linear discriminant\n",
    "class DiscriminantLineaire:\n",
    "    def __init__(self, eta=1e-2, epsilon=1e-2, max_iter=1000):\n",
    "\n",
    "        # Cette fonction est déjà codée, utilisez les variables membres\n",
    "        # qu'elle définit dans les autres fonctions\n",
    "        # This function is already coded, use the member variables it\n",
    "        # defines in other functions\n",
    "        self.eta = eta\n",
    "        \n",
    "        # Epsilon et max_iter sont des paramètres du critère d'arrêt\n",
    "        # max_iter est le nombre maximum de mises à jour des poids,\n",
    "        # alors qu'epsilon est un seuil sur la différent minimale entre les\n",
    "        # erreurs faites entre deux itérations consécutives pour continuer l'entraînement\n",
    "        # Epsilon and max_iter are parameters for the stop criterion\n",
    "        # max_iter is the maximum number of weights updates allowed, while\n",
    "        # epsilon is a threshold on the minimum error difference observed between\n",
    "        # two consecutive training steps.\n",
    "        self.epsilon = epsilon\n",
    "        self.max_iter = max_iter\n",
    "     \n",
    "    def hypothesis(self, X, w):\n",
    "        h = X.dot(w[1:]) + w[0]\n",
    "        return h.reshape((h.shape[0], 1))\n",
    "        \n",
    "    def e(self, X, r, h):\n",
    "        return (r - h)/numpy.linalg.norm(X)**2\n",
    "    \n",
    "    def cost(self, X, r, h):\n",
    "        return (1/2)*numpy.sum(((r - h)/numpy.linalg.norm(X))**2)\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Implémentez la fonction d'entraînement selon les équations développées\n",
    "        # à la question précédente.\n",
    "        # Implement the training function according to the equations developed at the\n",
    "        # previous question\n",
    "\n",
    "        # On initialise les poids aléatoirement\n",
    "        # Weights are randomly initialized\n",
    "        w = numpy.random.rand(X.shape[1]+1)\n",
    "        w = w.reshape((w.shape[0], 1))\n",
    "        \n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        c = [0]\n",
    "\n",
    "        # *** TODO Q2B ***\n",
    "        # Implémentez ici l'entraînement dans la boucle suivante,\n",
    "        # qui se répète self.max_iter fois.\n",
    "        # Vous êtes libres d'utiliser les noms de variable de votre choix, sauf\n",
    "        # pour les poids qui doivent être contenus dans la variable w définie plus haut\n",
    "        # Implement here the training in the following loop, which is \n",
    "        # repeated self.max_iter times\n",
    "        # You are free to use the variables names of your choice, except\n",
    "        # for the weights, which should be put in variable w defined above\n",
    "        for i in range(self.max_iter):\n",
    "            h = self.hypothesis(X, w)\n",
    "            r = numpy.array(numpy.where(y==0, 1, -1))\n",
    "            \n",
    "            f = numpy.where(r*h < 0, True, False)\n",
    "            _Xf = X[numpy.broadcast_to(f, X.shape)]\n",
    "            _Xf = _Xf.reshape((int(_Xf.shape[0]/X.shape[1]), X.shape[1]))\n",
    "            e = self.e(_Xf, r[f], h[f])\n",
    "\n",
    "            w[1:] = w[1:] + self.eta * numpy.sum(_Xf.T.dot(e))\n",
    "            w[0] = w[0] + self.eta * numpy.sum(e)\n",
    "            \n",
    "            c.append(self.cost(_Xf, r[f], h[f]))\n",
    "            if numpy.isclose(c[i], c[i-1], atol=self.epsilon):\n",
    "                print(\"Valeur de la différence des erreurs à la sortie \\\n",
    "                      \\n Iteration=\", i, \", {0} - {1} = {2}\".format(c[i], c[i-1], c[i]-c[i-1]))\n",
    "                break\n",
    "            \n",
    "        # ******\n",
    "        # Copie des poids entraînés dans une variable membre pour les conserver\n",
    "        # Copy trained weights in a member variable for storing\n",
    "        self.w = w\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # *** TODO Q2B ***\n",
    "        # Implémentez la fonction de prédiction\n",
    "        # Implement the prediction function\n",
    "        h = self.hypothesis(X, self.w)\n",
    "        return numpy.where(h >= 0, 1, -1)\n",
    "        \n",
    "        # ******\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        # *** TODO Q2B ***\n",
    "        # Implémentez la fonction retournant le score (précision / accuracy)\n",
    "        # du classifieur sur les données reçues en argument.\n",
    "        # Vous pouvez supposer que fit() a préalablement été exécuté\n",
    "        # Indice : réutiliser votre implémentation de predict() réduit de\n",
    "        # beaucoup la taille de cette fonction!\n",
    "        # Implement the function returning the classifier score (accuracy)\n",
    "        # on data received as argument.\n",
    "        # You can assume that fit() has been executed before\n",
    "        # Tip: reusing your implementation of predict() reduce significantly the \n",
    "        # size of this function!\n",
    "        y = y.reshape((y.shape[0], 1))\n",
    "        r = numpy.array(numpy.where(y==0, 1, -1))\n",
    "        return numpy.sum(numpy.where(r*self.predict(X) >= 0, 1, 0))/r.shape[0]\n",
    "        # ******"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2077dec",
   "metadata": {
    "editable": false,
    "id": "004150e6",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "## Q2C\n",
    "Testez la performance de ce discriminant linéaire sur un jeu de données synthétique à 2 classes, produit avec la fonction `make_classification` de la librairie *Scikit-learn* (100 instances selon deux classes et en deux dimensions, avec un cluster par classe). Comme l'exercice se limite à valider le bon fonctionnement du classifieur, rapportez les résultats sur l'ensemble des données. Cela signifie que vous incluez également les données d'entraînement pour calculer la performance.\n",
    "\n",
    "Vous devez:\n",
    "- Afficher le score du classifieur\n",
    "- Tracer les différentes régions de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a3ef5",
   "metadata": {
    "editable": false,
    "id": "1f99714f",
    "lang": "en",
    "tags": []
   },
   "source": [
    "## Q2C\n",
    "Test the performance of this linear discriminant on a synthetic 2-class dataset, produced with the `make_classification` function of the *Scikit-learn* library (100 instances according to two classes and in two dimensions, with one cluster per class). As the exercise is limited to validating the classifier, report the results on the whole data set. This means that you also include the training data to calculate the performance.\n",
    "\n",
    "You must:\n",
    "- Display the classifier score\n",
    "- Plot the different decision regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc18db7",
   "metadata": {
    "editable": false,
    "id": "dcc5703d",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "### Patron de code réponse à l'exercice Q2C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d231812",
   "metadata": {
    "editable": false,
    "id": "c8d8186a",
    "lang": "en",
    "tags": []
   },
   "source": [
    "### Q2C answer code template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c94a3c1",
   "metadata": {
    "editable": false,
    "id": "5bada020",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Durée d'exécution maximale / maximum execution time\n",
    "TMAX_Q2C = 10.0\n",
    "_times.append(time.time())\n",
    "\n",
    "# Problème à 2 classes / 2-class problem\n",
    "X, y = make_classification(n_features=2,\n",
    "                           n_redundant=0,\n",
    "                           n_informative=2,\n",
    "                           n_clusters_per_class=1)\n",
    "\n",
    "# *** TODO Q2C ***\n",
    "# Créez ici une grille permettant d'afficher les régions de\n",
    "# décision pour chaque classifieur\n",
    "# Indice : numpy.meshgrid pourrait vous être utile ici\n",
    "# N'utilisez pas un pas trop petit!\n",
    "\n",
    "# Create a grid here to display the decision regions for each\n",
    "# decision regions for each classifier\n",
    "# Tip: numpy.meshgrid might be useful here\n",
    "# Don't use a too small step size!\n",
    "\n",
    "# Entraînez le discriminant linéaire implémenté\n",
    "# Train the implemented linear discriminant\n",
    "\n",
    "# Testez la performance du discriminant linéaire pour le problème\n",
    "# Test the performance of the linear discriminant for the problem\n",
    "\n",
    "# Création de la figure à afficher\n",
    "# Create the figure to display\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Utilisez la grille que vous avez créée plus haut\n",
    "# pour afficher les régions de décision, de même\n",
    "# que les points colorés selon leur vraie classe\n",
    "# N'oubliez pas la légende !\n",
    "# Use the grid you created above\n",
    "# to display the decision regions, as well as\n",
    "# coloured points according to their true class\n",
    "# Don't forget the legend!\n",
    "\n",
    "ax.set_title(\"Title\")   # À modifier / to be modified\n",
    "ax.set_xlabel(\"X Axis\") # À modifier / to be modified\n",
    "ax.set_ylabel(\"Y Axis\") # À modifier / to be modified\n",
    "#ax.contourf() # À compléter / to be completed\n",
    "#ax.scatter()  # À compléter / to be completed\n",
    "\n",
    "# ******\n",
    "\n",
    "_times.append(time.time())\n",
    "checkTime(TMAX_Q2C, \"Q2C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d47e203",
   "metadata": {
    "editable": false,
    "id": "0fe32fae",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "### Entrez votre solution à Q2C dans la cellule ci-dessous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a08a3e",
   "metadata": {
    "editable": false,
    "id": "14ff9fa5",
    "lang": "en",
    "tags": []
   },
   "source": [
    "### Enter your answer to Q2C in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f13f8",
   "metadata": {
    "deletable": false,
    "id": "e64f82ca",
    "tags": [
     "user-answer-D2Q2C",
     "editable"
    ]
   },
   "outputs": [],
   "source": [
    "# Durée d'exécution maximale / maximum execution time\n",
    "TMAX_Q2C = 10.0\n",
    "_times.append(time.time())\n",
    "\n",
    "# Problème à 2 classes / 2-class problem\n",
    "X, y = make_classification(n_features=2,\n",
    "                           n_redundant=0,\n",
    "                           n_informative=2,\n",
    "                           n_clusters_per_class=1)\n",
    "\n",
    "# *** TODO Q2C ***\n",
    "# Créez ici une grille permettant d'afficher les régions de\n",
    "# décision pour chaque classifieur\n",
    "# Indice : numpy.meshgrid pourrait vous être utile ici\n",
    "# N'utilisez pas un pas trop petit!\n",
    "# Create a grid here to display the decision regions for each\n",
    "# decision regions for each classifier\n",
    "# Tip: numpy.meshgrid might be useful here\n",
    "# Don't use a too small step size!\n",
    "h = .02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = numpy.meshgrid(numpy.arange(x_min, x_max, h),\n",
    "numpy.arange(y_min, y_max, h))\n",
    "\n",
    "# Entraînez le discriminant linéaire implémenté\n",
    "# Train the implemented linear discriminant\n",
    "my_clf = DiscriminantLineaire(epsilon=1e-6)\n",
    "\n",
    "y = y.reshape((y.shape[0], 1))\n",
    "my_clf.fit(X, y)\n",
    "\n",
    "# Testez la performance du discriminant linéaire pour le problème\n",
    "# Test the performance of the linear discriminant for the problem\n",
    "score = my_clf.score(X, y)\n",
    "print(\"score=\",score)\n",
    "\n",
    "# Création de la figure à afficher\n",
    "# Create the figure to display\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Utilisez la grille que vous avez créée plus haut\n",
    "# pour afficher les régions de décision, de même\n",
    "# que les points colorés selon leur vraie classe\n",
    "# N'oubliez pas la légende !\n",
    "# Use the grid you created above\n",
    "# to display the decision regions, as well as\n",
    "# coloured points according to their true class\n",
    "# Don't forget the legend!\n",
    "colors = numpy.array([x for x in \"bgrcmyk\"])\n",
    "\n",
    "pred = my_clf.predict(numpy.c_[xx.ravel(), yy.ravel()])  \n",
    "pred = pred.reshape(xx.shape)\n",
    "\n",
    "ax.set_title(\"Discriminant linéaire\")   # À modifier / to be modified\n",
    "ax.set_xlabel(\"Feature1 Axis\") # À modifier / to be modified\n",
    "ax.set_ylabel(\"Feature2 Axis\") # À modifier / to be modified\n",
    "ax.contourf(xx, yy, pred, cmap=pyplot.cm.Paired, alpha=0.1)\n",
    "ax.scatter(X[:, 0], X[:, 1], cmap=pyplot.cm.Paired, c=colors[y].reshape(-1))\n",
    "\n",
    "pyplot.xlim(xx.min(), xx.max())\n",
    "pyplot.ylim(yy.min(), yy.max())\n",
    "pyplot.show()\n",
    "\n",
    "# ******\n",
    "\n",
    "_times.append(time.time())\n",
    "checkTime(TMAX_Q2C, \"Q2C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e23857",
   "metadata": {
    "editable": false,
    "id": "1b64c29c",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "## Q2D\n",
    "Comparez les résultats de votre classifieur avec les discriminants linéaires suivants:\n",
    "  - Méthode paramétrique de loi normale multivariée (`discriminant_analysis.LinearDiscriminantAnalysis`);\n",
    "  - Descente du gradient avec le critère du perceptron (`linear_model.Perceptron`);\n",
    "  - Régression logistique (`linear_model.LogisticRegression`).\n",
    "\n",
    "Utilisez le jeu de données suivant pour faire vos comparaisons:\n",
    "- Breast Cancer Wisconsin: jeu de 569 données pour l'identification du cancer du sein en 30 dimensions et selon 2 classes. Le jeu est disponible avec la commande `load_breast_cancer()`.\n",
    "\n",
    "Normalisez préalablement les données selon les valeurs minimales et maximales du jeu avec la fonction appelée `minmax_scale`. Faites vos expérimentations selon une validation croisée à trois plis.\n",
    "\n",
    "Pour cette question:\n",
    "- Rapportez les taux d'erreurs en entraînement, en validation et le temps de calcul dans le tableau prévu à cet effet;\n",
    "- Commentez **<u>brièvement</u>** les résultats obtenus et indiquez les paramètres d'entraînement utilisés pour chacun des algorithmes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc46a84e",
   "metadata": {
    "editable": false,
    "id": "6660e041",
    "lang": "en",
    "tags": []
   },
   "source": [
    "## Q2D\n",
    "Compare the results of your classifier with the following linear discriminants:\n",
    "  - Parametric multivariate normal distribution method (`discriminant_analysis.LinearDiscriminantAnalysis`);\n",
    "  - Gradient descent with the perceptron criterion (`linear_model.Perceptron`);\n",
    "  - Logistic regression (`linear_model.LogisticRegression`).\n",
    "\n",
    "Use the following dataset to make your comparisons:\n",
    "- Breast Cancer Wisconsin: dataset of 569 instances for identifying breast cancer in 30 dimensions and according to 2 classes. The dataset is available with the command `load_breast_cancer()`.\n",
    "\n",
    "Normalize the data according to the minimum and maximum values of the set with the function called `minmax_scale`. Run your experiments according to a three-fold cross-validation.\n",
    "\n",
    "For this question:\n",
    "- Report the error rates in training, validation and computation time in the table provided;\n",
    "- Comment **<u>briefly</u>** the results obtained and indicate the training parameters used for each algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7004fa",
   "metadata": {
    "editable": false,
    "id": "fcc94def",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "### Patron de code réponse à l'exercice Q2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62a57fc",
   "metadata": {
    "editable": false,
    "id": "0fcb1e43",
    "lang": "en",
    "tags": []
   },
   "source": [
    "### Q2D answer code template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed70f25",
   "metadata": {
    "editable": false,
    "id": "cc913807",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Durée d'exécution maximale\n",
    "# Maximum execution duration\n",
    "TMAX_Q2D = 60\n",
    "\n",
    "# Dictionnaire pour enregistrer les paramètres évalués\n",
    "# Dictionnary for recording evaluated parameters\n",
    "params = collections.defaultdict(list)\n",
    "params['classifier'] = []\n",
    "\n",
    "_times.append(time.time())\n",
    "\n",
    "# *** TODO Q2D ***\n",
    "\n",
    "# Chargez les données \"Breast cancer Wisconsin\" et normalisez les de\n",
    "# manière les valeurs minimum/maximum tiennent dans le domaine [0, 1]\n",
    "# Load \"Breast cancer Wisconsin\" dataset and normalize it in order to\n",
    "# get their minimum/maximum values in the [0, 1] domain\n",
    "\n",
    "# Comparez les diverses approches demandées dans l'énoncé sur Breast Cancer\n",
    "# Initialisez votre discriminant linéaire avec les paramètres suivants :\n",
    "# DiscriminantLineaire(eta=1e-4, epsilon=1e-6, max_iter=10000)\n",
    "# N'oubliez pas que l'évaluation doit être faite par une validation\n",
    "# croisée à K=3 plis!\n",
    "# Compare the various approaches requested in the statement on Breast Cancer\n",
    "# Initialize your linear discriminant with the following parameters:\n",
    "# DiscriminantLineaire(eta=1e-4, epsilon=1e-6, max_iter=10000)\n",
    "# Don't forget that the evaluation must be done by a cross validation \n",
    "# with K=3 folds!\n",
    "\n",
    "# Initialisation des différents classifieurs\n",
    "# Initialize the various classifiers\n",
    "classifiers = [DiscriminantLineaire(eta=1e-4, epsilon=1e-6, max_iter=10000),\n",
    "               LinearDiscriminantAnalysis(), # Ajustez les hyperparamètres! / Adjust the hyperparameters!\n",
    "               LogisticRegression(),         # Ajustez les hyperparamètres! / Adjust the hyperparameters!\n",
    "               Perceptron(),                 # Ajustez les hyperparamètres! / Adjust the hyperparameters!\n",
    "              ]\n",
    "\n",
    "# Création du tableau pour accumuler les résultats\n",
    "# Create the table to accumulate the results\n",
    "results = {'Classifiers':[],\n",
    "           'Train_err':[],\n",
    "           'Valid_err':[],\n",
    "           'Exec_time':[],\n",
    "           'Comments':[],\n",
    "          }\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    if clf_name not in results['Classifiers']:\n",
    "        results['Classifiers'].append(clf_name)\n",
    "    \n",
    "    # Boucle d'entraînement à faire\n",
    "    # Training loop to be done\n",
    "\n",
    "    # Validation croisée (K=3) à faire\n",
    "    # Cross-validation (K=3) to be done\n",
    "\n",
    "    # Mesure du temps d'exécution à faire\n",
    "    # Measuring execution time to be done\n",
    "\n",
    "    # Ajoutez l'erreur d'entraînement dans la variable train_err\n",
    "    # Add training error in variable train_err\n",
    "    train_err = 0  # Remplacez le 0 par la valeur / remplace the 0 with the value\n",
    "    results['Train_err'].append(train_err)  \n",
    "    \n",
    "    # Ajoutez l'erreur de validation dans la variable valid_err\n",
    "    # Add validation error in variable valid_err\n",
    "    valid_err = 0  # Remplacez le 0 par la valeur / remplace the 0 with the value\n",
    "    results['Valid_err'].append(valid_err)\n",
    "    \n",
    "    # Ajoutez le temps de calcul mesuré dans la variable exec_time\n",
    "    # Add measure execution time in variable exec_time\n",
    "    exec_time = 0  # Remplacer le 0 par la valeur / remplace the 0 with the value\n",
    "    results['Exec_time'].append(exec_time)\n",
    "\n",
    "# ******\n",
    "\n",
    "_times.append(time.time())\n",
    "checkTime(TMAX_Q2D, \"Q2D\")\n",
    "\n",
    "\n",
    "# *** TODO Q4C ***\n",
    "# Ajoutez les commentaires et les hyperparamètres\n",
    "# utilisés pour chaque classifieur demandé \n",
    "# Add comments and hyperparameters used for each\n",
    "# classifier requested\n",
    "\n",
    "# Ajoutez vos commentaires\n",
    "# Add your comments\n",
    "comments = \"Commentaires pour le \\\n",
    "            DiscriminantLineaire ici.\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# Ajoutez vos commentaires et HP pour le LinearDiscriminantAnalysis\n",
    "# Add your comments and HP for LinearDiscriminantAnalysis\n",
    "comments = \"Commentaires & HP pour le \\\n",
    "            LinearDiscriminantAnalysis ici.\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# Ajoutez vos commentaires et HP pour le LogisticRegression\n",
    "# Add your comments and HP for LogisticRegression\n",
    "comments = \"Commentaires & HP pour la \\\n",
    "            LogisticRegression ici.\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# Ajoutez vos commentaires et HP pour le Perceptron\n",
    "# Add your comments and HP for Perceptron\n",
    "comments = \"Commentaires & HP pour le \\\n",
    "            Perceptron ici.\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# *****\n",
    "\n",
    "\n",
    "# Affichage des erreurs\n",
    "df = pandas.DataFrame(results)\n",
    "display.display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb403c2b",
   "metadata": {
    "editable": false,
    "id": "c6e1fc47",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "### Entrez votre solution à Q2D dans la cellule ci-dessous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eec44cb",
   "metadata": {
    "editable": false,
    "id": "fd592f81",
    "lang": "en",
    "tags": []
   },
   "source": [
    "### Enter your answer to Q2D in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c7c27e",
   "metadata": {
    "deletable": false,
    "id": "acad04f6",
    "tags": [
     "user-answer-D2Q2D",
     "editable"
    ]
   },
   "outputs": [],
   "source": [
    "# Durée d'exécution maximale\n",
    "# Maximum execution duration\n",
    "TMAX_Q2D = 60\n",
    "\n",
    "# Dictionnaire pour enregistrer les paramètres évalués\n",
    "# Dictionnary for recording evaluated parameters\n",
    "params = collections.defaultdict(list)\n",
    "params['classifier'] = []\n",
    "\n",
    "_times.append(time.time())\n",
    "\n",
    "# *** TODO Q2D ***\n",
    "\n",
    "# Chargez les données \"Breast cancer Wisconsin\" et normalisez les de\n",
    "# manière les valeurs minimum/maximum tiennent dans le domaine [0, 1]\n",
    "# Load \"Breast cancer Wisconsin\" dataset and normalize it in order to\n",
    "# get their minimum/maximum values in the [0, 1] domain\n",
    "breast_cancer_data = load_breast_cancer()\n",
    "X, y = breast_cancer_data.data, breast_cancer_data.target\n",
    "\n",
    "X = minmax_scale(X)\n",
    "\n",
    "# Comparez les diverses approches demandées dans l'énoncé sur Breast Cancer\n",
    "# Initialisez votre discriminant linéaire avec les paramètres suivants :\n",
    "# DiscriminantLineaire(eta=1e-4, epsilon=1e-6, max_iter=10000)\n",
    "# N'oubliez pas que l'évaluation doit être faite par une validation\n",
    "# croisée à K=3 plis!\n",
    "# Compare the various approaches requested in the statement on Breast Cancer\n",
    "# Initialize your linear discriminant with the following parameters:\n",
    "# DiscriminantLineaire(eta=1e-4, epsilon=1e-6, max_iter=10000)\n",
    "# Don't forget that the evaluation must be done by a cross validation \n",
    "# with K=3 folds!\n",
    "kf = KFold(n_splits=3, random_state=64567861, shuffle=True)\n",
    "\n",
    "# Initialisation des différents classifieurs\n",
    "# Initialize the various classifiers\n",
    "classifiers = [DiscriminantLineaire(eta=1e-4, epsilon=1e-6, max_iter=10000),\n",
    "               LinearDiscriminantAnalysis(solver='lsqr'),\n",
    "               LogisticRegression(penalty=\"none\", solver='lbfgs', multi_class='ovr', verbose=1, \n",
    "                                  max_iter=50, tol=1e-1, n_jobs=-1),         \n",
    "               Perceptron(eta0=1e-1, verbose=1, max_iter=100, tol=1e-4),\n",
    "              ]\n",
    "\n",
    "# Création du tableau pour accumuler les résultats\n",
    "# Create the table to accumulate the results\n",
    "results = {'Classifiers':[],\n",
    "           'Train_err':[],\n",
    "           'Valid_err':[],\n",
    "           'Exec_time':[],\n",
    "           'Comments':[],\n",
    "          }\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    if clf_name not in results['Classifiers']:\n",
    "        results['Classifiers'].append(clf_name)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    # Boucle d'entraînement à faire\n",
    "    # Training loop to be done\n",
    "    # Validation croisée (K=3) à faire\n",
    "    # Cross-validation (K=3) to be done\n",
    "    accuracy_0 = accuracy_1 = 0\n",
    "    count = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        accuracy_0 = 1 - clf.score(X_train, y_train)\n",
    "        accuracy_1 = 1 - clf.score(X_test, y_test)\n",
    "\n",
    "    # Mesure du temps d'exécution à faire\n",
    "    # Measuring execution time to be done\n",
    "    t2 = time.time()\n",
    "\n",
    "    # Ajoutez l'erreur d'entraînement dans la variable train_err\n",
    "    # Add training error in variable train_err\n",
    "    train_err = accuracy_0  # Remplacez le 0 par la valeur / remplace the 0 with the value\n",
    "    results['Train_err'].append(train_err)  \n",
    "    \n",
    "    # Ajoutez l'erreur de validation dans la variable valid_err\n",
    "    # Add validation error in variable valid_err\n",
    "    valid_err = accuracy_1  # Remplacez le 0 par la valeur / remplace the 0 with the value\n",
    "    results['Valid_err'].append(valid_err)\n",
    "    \n",
    "    # Ajoutez le temps de calcul mesuré dans la variable exec_time\n",
    "    # Add measure execution time in variable exec_time\n",
    "    exec_time = t2 - t1  # Remplacer le 0 par la valeur / remplace the 0 with the value\n",
    "    results['Exec_time'].append(exec_time)\n",
    "\n",
    "# ******\n",
    "\n",
    "_times.append(time.time())\n",
    "checkTime(TMAX_Q2D, \"Q2D\")\n",
    "\n",
    "\n",
    "# *** TODO Q4C ***\n",
    "# Ajoutez les commentaires et les hyperparamètres\n",
    "# utilisés pour chaque classifieur demandé \n",
    "# Add comments and hyperparameters used for each\n",
    "# classifier requested\n",
    "\n",
    "# Ajoutez vos commentaires\n",
    "# Add your comments\n",
    "comments = \"N'a pas pu atteindre son maximum, par conséquent a de mauvaises performances\\\n",
    "            Prend plus de temps pour s'exécuter que tout le reste \\\n",
    "            Les hyperparamètres ne sont donc pas à leurs valeurs optimales dans ce cas\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# Ajoutez vos commentaires et HP pour le LinearDiscriminantAnalysis\n",
    "# Add your comments and HP for LinearDiscriminantAnalysis\n",
    "comments = \"Train_err plus élévé que LogisticRegression et Perceptron mais moins élévé\\\n",
    "            que DiscriminantLineaire. Valid_err converge cependant vers \\\n",
    "            la même valeur que LogisticRegression et Perceptron, HP=(solver='lsqr')\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# Ajoutez vos commentaires et HP pour le LogisticRegression\n",
    "# Add your comments and HP for LogisticRegression\n",
    "comments = \"Donne les meilleures performances avec le plus de temps, \\\n",
    "            HP=(penalty='none', solver='lbfgs', multi_class='ovr', \\\n",
    "            verbose=1, max_iter=50, tol=1e-1, , n_jobs=-1)\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# Ajoutez vos commentaires et HP pour le Perceptron\n",
    "# Add your comments and HP for Perceptron\n",
    "comments = \"Donne des résultats légèrement similaires à la régression \\\n",
    "            linéaire mais avec beaucoup moins de temps, \\\n",
    "            HP=(eta0=1e-1, verbose=1, max_iter=20, tol=1e-4)\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# *****\n",
    "\n",
    "\n",
    "# Affichage des erreurs\n",
    "df = pandas.DataFrame(results)\n",
    "display.display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74bdf89",
   "metadata": {
    "editable": false,
    "id": "0c786abb",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "## Q2E\n",
    "Implémentez une classe Python encapsulant le classifieur `DiscriminantLineaire` fait précédemment, pour un traitement de type *un contre tous* pour faire du classement multiclasses. Programmez au minimum les fonctions `fit`, `predict` et `score` de l'interface de modèles de *scikit-learn*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44926c27",
   "metadata": {
    "editable": false,
    "id": "e55ff417",
    "lang": "en",
    "tags": []
   },
   "source": [
    "## Q2E\n",
    "Implement a Python class encapsulating the `DiscriminantLineaire` classifier previously done, for a *one against all* treatment to achieve multiclass classification. Code at least the `fit`, `predict` and `score` functions from the *scikit-learn* template interface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d95760",
   "metadata": {
    "editable": false,
    "id": "aa6c20d8",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "### Patron de code réponse à l'exercice Q2E"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b1ce3e",
   "metadata": {
    "editable": false,
    "id": "4f37fd78",
    "lang": "en",
    "tags": []
   },
   "source": [
    "### Q2E answer code template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd9a9e0",
   "metadata": {
    "editable": false,
    "id": "a1598799",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Implémentation du classifieur un contre utilisant le discriminant \n",
    "# linéaire défini précédemment\n",
    "# Implementation of the one-against-all classifier using the linear discriminant\n",
    "# defined previously\n",
    "class ClassifieurUnContreTous:\n",
    "    def __init__(self, n_classes, **kwargs):\n",
    "        # Cette fonction est déjà codée pour vous, vous n'avez qu'à utiliser\n",
    "        # les variables membres qu'elle définit dans les autres fonctions\n",
    "        # This function is already coded for you, you just have to use\n",
    "        # the member variables it defines in the other functions\n",
    "        self.n_classes = n_classes\n",
    "        self.estimators = [DiscriminantLineaire(**kwargs) for c in range(n_classes)]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # *** TODO Q2E ***\n",
    "        # Entraînez chaque classifieur (contenu dans self.estimators)\n",
    "        # pour distinguer une seule classe des autres\n",
    "        # Train each classifier (contained in self.estimators)\n",
    "        # to distinguish a single class from others\n",
    "\n",
    "        # Retirez le \"pass\" et compléter le code ici\n",
    "        # Remove the \"pass\" and complete the code here\n",
    "        pass\n",
    "        # ******\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # *** TODO Q2E ***\n",
    "        # Faire les prédictions selon l'approche un contre tous\n",
    "        # Vous pouvez supposer que fit() a préalablement été exécuté\n",
    "        # Make predictions using the one-to-many approach\n",
    "        # You can assume that fit() has been previously executed\n",
    "\n",
    "        # Retirez le \"pass\" et complétez le code ici\n",
    "        # Remove the \"pass\" and complete the code here\n",
    "        pass\n",
    "        # ******\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        # *** TODO Q2E ***\n",
    "        # Implémentez ici le calcul du score utilisant l'approche un contre tous\n",
    "        # Ce score correspond à la précision (accuracy) moyenne\n",
    "        # Vous pouvez supposer que fit() a préalablement été exécuté\n",
    "        # Implement here the calculation of the score using the one against all approach\n",
    "        # This score corresponds to the average accuracy\n",
    "        # You can assume that fit() has been previously executed\n",
    "\n",
    "        # Retirez le \"pass\" et complétez le code ici\n",
    "        # Remove the \"pass\" and complete the code here\n",
    "        pass\n",
    "        # ******"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96af057",
   "metadata": {
    "editable": false,
    "id": "ba42de70",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "### Entrez votre solution à Q2E dans la cellule ci-dessous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f0d62b",
   "metadata": {
    "editable": false,
    "id": "4ca84876",
    "lang": "en",
    "tags": []
   },
   "source": [
    "### Enter your answer to Q2E in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa92c8",
   "metadata": {
    "deletable": false,
    "id": "3fb31e01",
    "tags": [
     "user-answer-D2Q2E",
     "editable"
    ]
   },
   "outputs": [],
   "source": [
    "# Implémentation du classifieur un contre utilisant le discriminant \n",
    "# linéaire défini précédemment\n",
    "# Implementation of the one-against-all classifier using the linear discriminant\n",
    "# defined previously\n",
    "class ClassifieurUnContreTous:\n",
    "    def __init__(self, n_classes, **kwargs):\n",
    "        # Cette fonction est déjà codée pour vous, vous n'avez qu'à utiliser\n",
    "        # les variables membres qu'elle définit dans les autres fonctions\n",
    "        # This function is already coded for you, you just have to use\n",
    "        # the member variables it defines in the other functions\n",
    "        self.n_classes = n_classes\n",
    "        self.estimators = [DiscriminantLineaire(**kwargs) for c in range(n_classes)]\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # *** TODO Q2E ***\n",
    "        # Entraînez chaque classifieur (contenu dans self.estimators)\n",
    "        # pour distinguer une seule classe des autres\n",
    "        # Train each classifier (contained in self.estimators)\n",
    "        # to distinguish a single class from others\n",
    "\n",
    "        for i in range(len(self.estimators)):\n",
    "            _y = numpy.where(y==i, 0, 1)\n",
    "            self.estimators[i].fit(X, _y)\n",
    "        # ******\n",
    "    \n",
    "    def predict(self, X):\n",
    "        # *** TODO Q2E ***\n",
    "        # Faire les prédictions selon l'approche un contre tous\n",
    "        # Vous pouvez supposer que fit() a préalablement été exécuté\n",
    "        # Make predictions using the one-to-many approach\n",
    "        # You can assume that fit() has been previously executed\n",
    "\n",
    "        h = [estimator.predict(X) for estimator in self.estimators]\n",
    "        \n",
    "        predictions = []\n",
    "        for t in range(X.shape[0]):\n",
    "            label_c = -1\n",
    "            for i in range(len(h)):\n",
    "                if h[i][t] >=0:\n",
    "                    label_c = i\n",
    "                    for j in range(len(h)):\n",
    "                        if j != i:\n",
    "                            if h[j][t] >= 0:\n",
    "                                label_c = -1 # ambiguité -> rejet\n",
    "                                break\n",
    "            predictions.append(label_c)\n",
    "        return numpy.array(predictions)\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        # *** TODO Q2E ***\n",
    "        # Implémentez ici le calcul du score utilisant l'approche un contre tous\n",
    "        # Ce score correspond à la précision (accuracy) moyenne\n",
    "        # Vous pouvez supposer que fit() a préalablement été exécuté\n",
    "        # Implement here the calculation of the score using the one against all approach\n",
    "        # This score corresponds to the average accuracy\n",
    "        # You can assume that fit() has been previously executed\n",
    "\n",
    "        h = self.predict(X)\n",
    "        h = h.reshape((h.shape[0], 1))\n",
    "        return numpy.sum(numpy.where(y==h, 1, 0))/y.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f77e2d",
   "metadata": {
    "editable": false,
    "id": "391753ce",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "## Q2F\n",
    "Testez la performance de ce discriminant linéaire sur un jeu de données synthétique à 3 classes, produit avec la fonction `make_classification` de la librairie *Scikit-learn* (100 instances selon trois classes et en deux dimensions, avec un cluster par classe). Comme l'exercice se limite à valider le bon fonctionnement du classifieur, rapportez les résultats sur l'ensemble des données. Cela signifie que vous incluez également les données d'entraînement pour calculer la performance.\n",
    "\n",
    "Vous devez:\n",
    "- Afficher le score du classifieur\n",
    "- Tracer les différentes régions de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2917b1e",
   "metadata": {
    "editable": false,
    "id": "6ad176b7",
    "lang": "en",
    "tags": []
   },
   "source": [
    "## Q2F\n",
    "Test the performance of this linear discriminant on a synthetic 3-class dataset, produced with the `make_classification` function of the *Scikit-learn* library (100 instances according to three classes and in two dimensions, with one cluster per class). As the exercise is limited to validating the classifier, report the results on the whole data set. This means that you also include the training data to calculate the performance.\n",
    "\n",
    "You must:\n",
    "- Display the classifier score\n",
    "- Plot the different decision regions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef07519",
   "metadata": {
    "editable": false,
    "id": "8a49af6a",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "### Patron de code réponse à l'exercice Q2F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ebf35b",
   "metadata": {
    "editable": false,
    "id": "7afd01a3",
    "lang": "en",
    "tags": []
   },
   "source": [
    "### Q2F answer code template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7527f287",
   "metadata": {
    "editable": false,
    "id": "2eede8ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Durée d'exécution maximale / maximum execution time\n",
    "TMAX_Q2F = 10.0\n",
    "_times.append(time.time())\n",
    "\n",
    "# Problème à 3 classes / 3-class problem\n",
    "X, y = make_classification(n_features=2,\n",
    "                           n_redundant=0,\n",
    "                           n_informative=2,\n",
    "                           n_clusters_per_class=1,\n",
    "                           n_classes=3)\n",
    "\n",
    "# *** TODO Q2F ***\n",
    "# Créez ici une grille permettant d'afficher les régions de\n",
    "# décision pour chaque classifieur\n",
    "# Indice : numpy.meshgrid pourrait vous être utile ici\n",
    "# N'utilisez pas un pas trop petit!\n",
    "\n",
    "# Create a grid here to display the decision regions for each\n",
    "# decision regions for each classifier\n",
    "# Tip: numpy.meshgrid might be useful here\n",
    "# Don't use a too small step size!\n",
    "\n",
    "# Entraînez le modèle un contre tous implémenté\n",
    "# Train the implemented one-against-all model\n",
    "\n",
    "# Testez la performance du modèle pour le problème\n",
    "# Test the performance of the model for the problem\n",
    "\n",
    "# Création de la figure à afficher\n",
    "# Create the figure to display\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Utilisez la grille que vous avez créée plus haut\n",
    "# pour afficher les régions de décision, de même\n",
    "# que les points colorés selon leur vraie classe\n",
    "# N'oubliez pas la légende !\n",
    "# Use the grid you created above\n",
    "# to display the decision regions, as well as\n",
    "# coloured points according to their true class\n",
    "# Don't forget the legend!\n",
    "\n",
    "ax.set_title(\"Title\")   # À modifier / to be modified\n",
    "ax.set_xlabel(\"X Axis\") # À modifier / to be modified\n",
    "ax.set_ylabel(\"Y Axis\") # À modifier / to be modified\n",
    "#ax.contourf() # À compléter / to be completed\n",
    "#ax.scatter()  # À compléter / to be completed\n",
    "\n",
    "# ******\n",
    "\n",
    "_times.append(time.time())\n",
    "checkTime(TMAX_Q2F, \"Q2F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c150d211",
   "metadata": {
    "editable": false,
    "id": "b8a3f889",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "### Entrez votre solution à Q2F dans la cellule ci-dessous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32fcd3c",
   "metadata": {
    "editable": false,
    "id": "d6c8163a",
    "lang": "en",
    "tags": []
   },
   "source": [
    "### Enter your answer to Q2F in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9461e39b",
   "metadata": {
    "deletable": false,
    "id": "b9ab8c54",
    "tags": [
     "user-answer-D2Q2F",
     "editable"
    ]
   },
   "outputs": [],
   "source": [
    "# Durée d'exécution maximale / maximum execution time\n",
    "TMAX_Q2F = 10.0\n",
    "_times.append(time.time())\n",
    "\n",
    "# Problème à 3 classes / 3-class problem\n",
    "X, y = make_classification(n_features=2,\n",
    "                           n_redundant=0,\n",
    "                           n_informative=2,\n",
    "                           n_clusters_per_class=1,\n",
    "                           n_classes=3)\n",
    "\n",
    "# *** TODO Q2F ***\n",
    "# Créez ici une grille permettant d'afficher les régions de\n",
    "# décision pour chaque classifieur\n",
    "# Indice : numpy.meshgrid pourrait vous être utile ici\n",
    "# N'utilisez pas un pas trop petit!\n",
    "# Create a grid here to display the decision regions for each\n",
    "# decision regions for each classifier\n",
    "# Tip: numpy.meshgrid might be useful here\n",
    "# Don't use a too small step size!\n",
    "h = .02\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = numpy.meshgrid(numpy.arange(x_min, x_max, h),\n",
    "numpy.arange(y_min, y_max, h))\n",
    "\n",
    "# Entraînez le modèle un contre tous implémenté\n",
    "# Train the implemented one-against-all model\n",
    "my_clf = ClassifieurUnContreTous(n_classes=3, epsilon=1e-20)\n",
    "y = y.reshape((y.shape[0], 1))\n",
    "my_clf.fit(X, y)\n",
    "\n",
    "# Testez la performance du modèle pour le problème\n",
    "# Test the performance of the model for the problem\n",
    "score = my_clf.score(X, y)\n",
    "print(score)\n",
    "\n",
    "# Création de la figure à afficher\n",
    "# Create the figure to display\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# Utilisez la grille que vous avez créée plus haut\n",
    "# pour afficher les régions de décision, de même\n",
    "# que les points colorés selon leur vraie classe\n",
    "# N'oubliez pas la légende !\n",
    "# Use the grid you created above\n",
    "# to display the decision regions, as well as\n",
    "# coloured points according to their true class\n",
    "# Don't forget the legend!\n",
    "\n",
    "colors = numpy.array([x for x in \"bgrcmyk\"])\n",
    "\n",
    "pred = my_clf.predict(numpy.c_[xx.ravel(), yy.ravel()])  \n",
    "pred = pred.reshape(xx.shape)\n",
    "\n",
    "ax.set_title(\"Classifieur un contre tous\")   # À modifier / to be modified\n",
    "ax.set_xlabel(\"Feature1 Axis\") # À modifier / to be modified\n",
    "ax.set_ylabel(\"Feature2 Axis\") # À modifier / to be modified\n",
    "ax.contourf(xx, yy, pred, cmap=pyplot.cm.Paired, alpha=0.1)\n",
    "ax.scatter(X[:, 0], X[:, 1], cmap=pyplot.cm.Paired, c=colors[y].reshape(-1))\n",
    "\n",
    "pyplot.xlim(xx.min(), xx.max())\n",
    "pyplot.ylim(yy.min(), yy.max())\n",
    "pyplot.show()\n",
    "\n",
    "# ******\n",
    "\n",
    "_times.append(time.time())\n",
    "checkTime(TMAX_Q2F, \"Q2F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e24fe4",
   "metadata": {
    "editable": false,
    "id": "d83ccaf7",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "## Q2G\n",
    "Comparez les résultats de votre classifieur un contre tous avec les discriminants linéaires suivants:\n",
    "  - Méthode paramétrique de loi normale multivariée (`discriminant_analysis.LinearDiscriminantAnalysis`);\n",
    "  - Descente du gradient avec le critère du perceptron (`linear_model.Perceptron`);\n",
    "  - Régression logistique (`linear_model.LogisticRegression`).\n",
    "\n",
    "Utilisez le jeu de données suivant pour faire vos comparaisons:\n",
    "- Iris de Fisher: jeu de 150 données pour l'identification d'Iris, avec des données en 4 dimensions et selon 3 classes. Le jeu est disponible avec la commande `load_iris()`.\n",
    "\n",
    "Normalisez préalablement les données selon les valeurs minimales et maximales du jeu avec la fonction appelée `minmax_scale`. Faites vos expérimentations selon une validation croisée à trois plis.\n",
    "\n",
    "Pour cette question:\n",
    "- Rapportez les taux d'erreurs en entraînement, en validation et le temps de calcul dans le tableau prévu à cet effet;\n",
    "- Commentez **<u>brièvement</u>** les résultats obtenus et indiquez les paramètres d'entraînement utilisés pour chacun des algorithmes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf75f6",
   "metadata": {
    "editable": false,
    "id": "71c85bb7",
    "lang": "en",
    "tags": []
   },
   "source": [
    "## Q2G\n",
    "Compare the results of your one-against-all classifier with the following linear discriminants:\n",
    "  - Parametric multivariate normal distribution method (`discriminant_analysis.LinearDiscriminantAnalysis`);\n",
    "  - Gradient descent with the perceptron criterion (`linear_model.Perceptron`);\n",
    "  - Logistic regression (`linear_model.LogisticRegression`).\n",
    "\n",
    "Use the following dataset to make your comparisons:\n",
    "- Fisher's Iris: 150 data set for Iris identification, with data in 4 dimensions and according to 3 classes. The set is available with the command `load_iris()`.\n",
    "\n",
    "Normalize the data according to the minimum and maximum values of the set with the function called `minmax_scale`. Run your experiments according to a three-fold cross-validation.\n",
    "\n",
    "For this question:\n",
    "- Report the error rates in training, validation and computation time in the table provided;\n",
    "- Comment **<u>briefly</u>** the results obtained and indicate the training parameters used for each algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac702f",
   "metadata": {
    "editable": false,
    "id": "bed7e009",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "### Patron de code réponse à l'exercice Q2G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c17d8e",
   "metadata": {
    "editable": false,
    "id": "d4d929d9",
    "lang": "en",
    "tags": []
   },
   "source": [
    "### Q2G answer code template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5171d51",
   "metadata": {
    "editable": false,
    "id": "2e82d251",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Durée d'exécution maximale\n",
    "# Maximum execution duration\n",
    "TMAX_Q2G = 60\n",
    "\n",
    "# Dictionnaire pour enregistrer les paramètres évalués\n",
    "# Dictionnary for recording evaluated parameters\n",
    "params = collections.defaultdict(list)\n",
    "params['classifier'] = []\n",
    "\n",
    "_times.append(time.time())\n",
    "\n",
    "# *** TODO Q2G ***\n",
    "\n",
    "# Chargez les données Iris et normalisez les de\n",
    "# manière les valeurs minimum/maximum tiennent dans le domaine [0, 1]\n",
    "# Load Iris dataset and normalize it in order to\n",
    "# get their minimum/maximum values in the [0, 1] domain\n",
    "\n",
    "# Comparez les diverses approches demandées dans l'énoncé sur Iris\n",
    "# Initialisez votre discriminant linéaire selon un classement un contre tous\n",
    "# avec les paramètres suivants :\n",
    "# DiscriminantLineaire(eta=1e-4, epsilon=1e-6, max_iter=10000)\n",
    "# N'oubliez pas que l'évaluation doit être faite par une validation\n",
    "# croisée à K=3 plis!\n",
    "# Compare the various approaches requested in the statement on Iris\n",
    "# Initialize your one-against-all linear discriminant with the following parameters:\n",
    "# DiscriminantLineaire(eta=1e-4, epsilon=1e-6, max_iter=10000)\n",
    "# Don't forget that the evaluation must be done by a cross validation \n",
    "# with K=3 folds!\n",
    "\n",
    "# Initialisation des différents classifieurs\n",
    "# Initialize the various classifiers\n",
    "classifiers = [ClassifieurUnContreTous(n_classes=3, eta=1e-4, epsilon=1e-6, max_iter=10000),\n",
    "               LinearDiscriminantAnalysis(), # Ajustez les hyperparamètres! / Adjust the hyperparameters!\n",
    "               LogisticRegression(),         # Ajustez les hyperparamètres! / Adjust the hyperparameters!\n",
    "               Perceptron(),                 # Ajustez les hyperparamètres! / Adjust the hyperparameters!\n",
    "              ]\n",
    "\n",
    "# Création du tableau pour accumuler les résultats\n",
    "# Create the table to accumulate the results\n",
    "results = {'Classifiers':[],\n",
    "           'Train_err':[],\n",
    "           'Valid_err':[],\n",
    "           'Exec_time':[],\n",
    "           'Comments':[],\n",
    "          }\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    if clf_name not in results['Classifiers']:\n",
    "        results['Classifiers'].append(clf_name)\n",
    "    \n",
    "    # Boucle d'entraînement à faire\n",
    "    # Training loop to be done\n",
    "\n",
    "    # Validation croisée (K=3) à faire\n",
    "    # Cross-validation (K=3) to be done\n",
    "\n",
    "    # Mesure du temps d'exécution à faire\n",
    "    # Measuring execution time to be done\n",
    "\n",
    "    # Ajoutez l'erreur d'entraînement dans la variable train_err\n",
    "    # Add training error in variable train_err\n",
    "    train_err = 0  # Remplacez le 0 par la valeur / remplace the 0 with the value\n",
    "    results['Train_err'].append(train_err)  \n",
    "    \n",
    "    # Ajoutez l'erreur de validation dans la variable valid_err\n",
    "    # Add validation error in variable valid_err\n",
    "    valid_err = 0  # Remplacer le 0 par la valeur / remplace the 0 with the value\n",
    "    results['Valid_err'].append(valid_err)\n",
    "    \n",
    "    # Ajoutez le temps de calcul mesuré dans la variable exec_time\n",
    "    # Add measure execution time in variable exec_time\n",
    "    exec_time = 0  # Remplacez le 0 par la valeur / remplace the 0 with the value\n",
    "    results['Exec_time'].append(exec_time)\n",
    "\n",
    "# ******\n",
    "\n",
    "_times.append(time.time())\n",
    "checkTime(TMAX_Q2G, \"Q2G\")\n",
    "\n",
    "\n",
    "# *** TODO Q2G ***\n",
    "# Ajoutez les commentaires et les hyperparamètres\n",
    "# utilisés pour chaque classifieur demandé \n",
    "# Add comments and hyperparameters used for each\n",
    "# classifier requested\n",
    "\n",
    "# Ajoutez vos commentaires\n",
    "# Add your comments\n",
    "comments = \"Commentaires pour le \\\n",
    "            ClassifieurUnContreTous ici.\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# Ajoutez vos commentaires et HP pour le LinearDiscriminantAnalysis\n",
    "# Add your comments and HP for LinearDiscriminantAnalysis\n",
    "comments = \"Commentaires & HP pour le \\\n",
    "            LinearDiscriminantAnalysis ici.\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# Ajoutez vos commentaires et HP pour le LogisticRegression\n",
    "# Add your comments and HP for LogisticRegression\n",
    "comments = \"Commentaires & HP pour la \\\n",
    "            LogisticRegression ici.\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# Ajoutez vos commentaires et HP pour le Perceptron\n",
    "# Add your comments and HP for Perceptron\n",
    "comments = \"Commentaires & HP pour le \\\n",
    "            Perceptron ici.\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# *****\n",
    "\n",
    "\n",
    "# Affichage des erreurs\n",
    "df = pandas.DataFrame(results)\n",
    "display.display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3906e08d",
   "metadata": {
    "editable": false,
    "id": "1dfdb5e2",
    "lang": "fr",
    "tags": []
   },
   "source": [
    "### Entrez votre solution à Q2G dans la cellule ci-dessous"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd5dc99",
   "metadata": {
    "editable": false,
    "id": "ae13f2b9",
    "lang": "en",
    "tags": []
   },
   "source": [
    "### Enter your answer to Q2G in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4683fe",
   "metadata": {
    "deletable": false,
    "id": "be4a5467",
    "tags": [
     "user-answer-D2Q2G",
     "editable"
    ]
   },
   "outputs": [],
   "source": [
    "# Durée d'exécution maximale\n",
    "# Maximum execution duration\n",
    "TMAX_Q2G = 60\n",
    "\n",
    "# Dictionnaire pour enregistrer les paramètres évalués\n",
    "# Dictionnary for recording evaluated parameters\n",
    "params = collections.defaultdict(list)\n",
    "params['classifier'] = []\n",
    "\n",
    "_times.append(time.time())\n",
    "\n",
    "# *** TODO Q2G ***\n",
    "\n",
    "# Chargez les données Iris et normalisez les de\n",
    "# manière les valeurs minimum/maximum tiennent dans le domaine [0, 1]\n",
    "# Load Iris dataset and normalize it in order to\n",
    "# get their minimum/maximum values in the [0, 1] domain\n",
    "iris_data = load_iris()\n",
    "X, y = iris_data.data, iris_data.target\n",
    "\n",
    "X = minmax_scale(X)\n",
    "\n",
    "# Comparez les diverses approches demandées dans l'énoncé sur Iris\n",
    "# Initialisez votre discriminant linéaire selon un classement un contre tous\n",
    "# avec les paramètres suivants :\n",
    "# DiscriminantLineaire(eta=1e-4, epsilon=1e-6, max_iter=10000)\n",
    "# N'oubliez pas que l'évaluation doit être faite par une validation\n",
    "# croisée à K=3 plis!\n",
    "# Compare the various approaches requested in the statement on Iris\n",
    "# Initialize your one-against-all linear discriminant with the following parameters:\n",
    "# DiscriminantLineaire(eta=1e-4, epsilon=1e-6, max_iter=10000)\n",
    "# Don't forget that the evaluation must be done by a cross validation \n",
    "# with K=3 folds!\n",
    "kf = KFold(n_splits=3, random_state=64567861, shuffle=True)\n",
    "\n",
    "# Initialisation des différents classifieurs\n",
    "# Initialize the various classifiers\n",
    "classifiers = [ClassifieurUnContreTous(n_classes=3, eta=1e-4, epsilon=1e-6, max_iter=10000),\n",
    "               LinearDiscriminantAnalysis(solver='lsqr'),\n",
    "               LogisticRegression(penalty=\"none\", solver='lbfgs', multi_class='ovr', verbose=1, \n",
    "                                  max_iter=100, tol=1e-1, n_jobs=-1),         \n",
    "               Perceptron(eta0=1e-1, verbose=1, max_iter=100, tol=1e-4),\n",
    "              ]\n",
    "\n",
    "# Création du tableau pour accumuler les résultats\n",
    "# Create the table to accumulate the results\n",
    "results = {'Classifiers':[],\n",
    "           'Train_err':[],\n",
    "           'Valid_err':[],\n",
    "           'Exec_time':[],\n",
    "           'Comments':[],\n",
    "          }\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf_name = clf.__class__.__name__\n",
    "    if clf_name not in results['Classifiers']:\n",
    "        results['Classifiers'].append(clf_name)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    # Boucle d'entraînement à faire\n",
    "    # Training loop to be done\n",
    "    # Validation croisée (K=3) à faire\n",
    "    # Cross-validation (K=3) to be done\n",
    "    accuracy_0 = accuracy_1 = 0\n",
    "    count = 0\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        accuracy_0 = 1 - clf.score(X_train, y_train)\n",
    "        accuracy_1 = 1 - clf.score(X_test, y_test)\n",
    "\n",
    "    # Mesure du temps d'exécution à faire\n",
    "    # Measuring execution time to be done\n",
    "    t2 = time.time()\n",
    "\n",
    "    # Ajoutez l'erreur d'entraînement dans la variable train_err\n",
    "    # Add training error in variable train_err\n",
    "    train_err = accuracy_0  # Remplacez le 0 par la valeur / remplace the 0 with the value\n",
    "    results['Train_err'].append(train_err)  \n",
    "    \n",
    "    # Ajoutez l'erreur de validation dans la variable valid_err\n",
    "    # Add validation error in variable valid_err\n",
    "    valid_err = accuracy_1  # Remplacez le 0 par la valeur / remplace the 0 with the value\n",
    "    results['Valid_err'].append(valid_err)\n",
    "    \n",
    "    # Ajoutez le temps de calcul mesuré dans la variable exec_time\n",
    "    # Add measure execution time in variable exec_time\n",
    "    exec_time = t2 - t1  # Remplacer le 0 par la valeur / remplace the 0 with the value\n",
    "    results['Exec_time'].append(exec_time)\n",
    "\n",
    "# ******\n",
    "\n",
    "_times.append(time.time())\n",
    "checkTime(TMAX_Q2D, \"Q2D\")\n",
    "\n",
    "\n",
    "# *** TODO Q4C ***\n",
    "# Ajoutez les commentaires et les hyperparamètres\n",
    "# utilisés pour chaque classifieur demandé \n",
    "# Add comments and hyperparameters used for each\n",
    "# classifier requested\n",
    "\n",
    "# Ajoutez vos commentaires\n",
    "# Add your comments\n",
    "comments = \"Très mauvaises performances avec des valeurs négatives en Train_err et valid_err\\\n",
    "            Prend beaucoup plus de temps à s'exécuter que tout le reste, valeurs de HP non optimales\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# Ajoutez vos commentaires et HP pour le LinearDiscriminantAnalysis\n",
    "# Add your comments and HP for LinearDiscriminantAnalysis\n",
    "comments = \"Meilleures performances avec le moins de temps, HP=(solver='lsqr')\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# Ajoutez vos commentaires et HP pour le LogisticRegression\n",
    "# Add your comments and HP for LogisticRegression\n",
    "comments = \"Résultat assez similaire à LinearDiscriminantAnalysis lors de la validation, \\\n",
    "            HP=(penalty='none', solver='lbfgs', multi_class='ovr', \\\n",
    "            verbose=1, max_iter=50, tol=1e-1, , n_jobs=-1)\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# Ajoutez vos commentaires et HP pour le Perceptron\n",
    "# Add your comments and HP for Perceptron\n",
    "comments = \"Erreur allant jusqu'à 22% à la validation. \\\n",
    "            linéaire mais avec beaucoup moins de temps, \\\n",
    "            HP=(eta0=1e-1, verbose=1, max_iter=100, tol=1e-4)\"\n",
    "results['Comments'].append(comments)\n",
    "\n",
    "# *****\n",
    "\n",
    "\n",
    "# Affichage des erreurs\n",
    "df = pandas.DataFrame(results)\n",
    "display.display(df)"
   ]
  }
 ],
 "metadata": {
  "PAX": {
   "userLang": "fr"
  },
  "celltoolbar": "",
  "jupytext": {
   "formats": "ipynb,md",
   "notebook_metadata_filter": "celltoolbar",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.3",
    "jupytext_version": "1.11.4"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (PAX)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
